# -*- coding: utf-8 -*-
"""hybrid-movie-recommender.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Qp5p0DdV6p2aZX9FV39zXNyLElAAuMtN

# **Phase 1: Setup**

Importing required libraries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import os

"""Downloading the dataset"""

!wget http://files.grouplens.org/datasets/movielens/ml-100k.zip
!unzip -o ml-100k.zip

"""Load ratings"""

ratings_cols = ['user_id', 'movie_id', 'rating', 'timestamp']
ratings = pd.read_csv('ml-100k/u.data', sep='\t', names=ratings_cols)
ratings.head()

"""Load movies data"""

movies_cols = ['movie_id', 'title', 'release_date', 'video_release_date',
               'IMDb_URL', 'unknown', 'Action', 'Adventure', 'Animation',
               'Children', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy',
               'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance',
               'Sci-Fi', 'Thriller', 'War', 'Western']

movies = pd.read_csv('ml-100k/u.item', sep='|', names=movies_cols, encoding='latin-1')
movies.head()

"""Basic stats"""

num_users = ratings['user_id'].nunique()
num_movies = ratings['movie_id'].nunique()
print("Number of users:", num_users)
print("Number of movies:", num_movies)

"""Rating distribution graph"""

ratings['rating'].value_counts().sort_index().plot(kind='bar', title='Rating Distribution')
plt.xlabel('Rating')
plt.ylabel('Count')
plt.show()

"""Calculating sparsity of user-movie matrix"""

sparsity = 1 - len(ratings) / (num_users * num_movies)
print("Sparsity of user-movie matrix:", sparsity)

"""# **Phase 2 : EDA**

Loading dataset
"""

ratings_cols = ['user_id', 'movie_id', 'rating', 'timestamp']
ratings = pd.read_csv('ml-100k/u.data', sep='\t', names=ratings_cols)

"""Ratings per user plot"""

ratings_per_user = ratings.groupby('user_id')['rating'].count()
ratings_per_user.plot(kind='hist', bins=20, title='Ratings per User')
plt.xlabel('Number of Ratings')
plt.ylabel('Number of Users')
plt.show()

"""Ratings per movie plot"""

ratings_per_movie = ratings.groupby('movie_id')['rating'].count()
ratings_per_movie.plot(kind='hist', bins=20, title='Ratings per Movie')
plt.xlabel('Number of Ratings')
plt.ylabel('Number of Movies')
plt.show()

"""Listing top movies by avg rating"""

top_movies = ratings.groupby('movie_id')['rating'].mean().sort_values(ascending=False).head(10)
print("Top 10 highest average rated movies:")
print(movies[movies['movie_id'].isin(top_movies.index)][['title']])

"""# **Phase 3 : Baseline Recommender**"""

movie_mean_ratings = ratings.groupby('movie_id')['rating'].mean()

movie_rating_count = ratings.groupby('movie_id')['rating'].count()

movie_popularity_scores = (0.7 * movie_mean_ratings) + (0.3 * movie_rating_count)

def popularity_recommender(top_n=10):
    top_movies = movie_popularity_scores.sort_values(ascending=False).head(top_n).index
    return movies[movies['movie_id'].isin(top_movies)][['movie_id','title']]

print("Top 10 Popular Movies:")
popularity_recommender()

"""## Item based collaborative filtering

Importing required libraries
"""

from sklearn.metrics.pairwise import cosine_similarity

#Creating user-item matrix
user_item_matrix = ratings.pivot(index='user_id', columns='movie_id', values='rating').fillna(0)

#Compute item-item similarity
item_similarity = cosine_similarity(user_item_matrix.T)  # Transpose to compare movies
item_similarity_df = pd.DataFrame(item_similarity, index=user_item_matrix.columns, columns=user_item_matrix.columns)

"""Creating function for item based recommendations"""

def item_based_recommender(user_id, top_n=10):

    user_ratings = user_item_matrix.loc[user_id]

    scores = item_similarity_df.dot(user_ratings) # compute predicted scores

    scores = scores[user_ratings == 0] # remove already rated movies

    top_items = scores.sort_values(ascending=False).head(top_n).index # display top n movies

    return movies[movies['movie_id'].isin(top_items)][['movie_id','title']]

"""Testing item based recommender"""

print("Item-based Recommendations for User 1:")
item_based_recommender(1)

"""# **Phase - 4 : Collaborative Filtering using Matrix Factorisation(Singular Value Decomposition)**

Installing and importing required libraries
"""

!pip install scikit-surprise

from surprise import Dataset, Reader, SVD
from surprise.model_selection import train_test_split
from surprise import accuracy

"""Convert data for surprise"""

reader = Reader(rating_scale=(1, 5))
data = Dataset.load_from_df(ratings[['user_id', 'movie_id', 'rating']], reader)

"""Train-test split"""

trainset, testset = train_test_split(data, test_size=0.2, random_state=42)

"""Building SVD model"""

model = SVD(n_factors=50, n_epochs=20, lr_all=0.005, reg_all=0.02)

"""Training the model"""

model.fit(trainset)

"""Evaluating along with RMSE(root mean squared error)"""

predictions = model.test(testset)
rmse = accuracy.rmse(predictions)

"""Function for making recommendations to a user"""

all_movie_ids = ratings['movie_id'].unique()

def svd_recommender(user_id, top_n=10):
    rated_movies = ratings[ratings['user_id'] == user_id]['movie_id']

    # predict ratings for unseen movies
    predictions = []
    for movie_id in all_movie_ids:
        if movie_id not in rated_movies.values:
            pred = model.predict(user_id, movie_id)
            predictions.append((movie_id, pred.est))

    # sort and retun top n movies
    predictions.sort(key=lambda x: x[1], reverse=True)
    top_movie_ids = [movie_id for movie_id, _ in predictions[:top_n]]

    return movies[movies['movie_id'].isin(top_movie_ids)][['movie_id','title']]

"""Testing the SVD Recommender"""

print("SVD Recommendations for User 1:")
svd_recommender(1)

"""# **Phase 5 : Content Based Recommender**

Creating genre feature matrix
"""

genre_cols = movies_cols[5:]
genre_matrix = movies[genre_cols]

"""Computing movie-movie similarity"""

genre_similarity = cosine_similarity(genre_matrix)
genre_similarity_df = pd.DataFrame(
    genre_similarity,
    index=movies['movie_id'],
    columns=movies['movie_id']
)

genre_similarity_df[50][172]  #testing

"""Building content based recommender function"""

def content_based_recommender(user_id, top_n=10):
  #getting movies liked by the user
    user_ratings = ratings[ratings['user_id'] == user_id]
    liked_movies = user_ratings[user_ratings['rating'] >= 4]['movie_id']

  #computing similarity scores
    scores = pd.Series(0, index=movies['movie_id'])
    for movie_id in liked_movies:
        scores += genre_similarity_df[movie_id]
    scores = scores[~scores.index.isin(user_ratings['movie_id'])] #removing already seen movies

  #returning top N movies
    top_movie_ids = scores.sort_values(ascending=False).head(top_n).index
    return movies[movies['movie_id'].isin(top_movie_ids)][['movie_id','title']]

"""Testing content based recommender"""

print("Content-based Recommendations for User 1:")
content_based_recommender(1)

"""# **Phase 6 : Hybrid Recommender(Collaborative filtering + content based)**

Collaborative filtering score function using SVD
"""

def get_cf_scores(user_id):
    """
    Predict ratings for all movies the user has NOT rated using SVD
    """
    rated_movies = ratings[ratings['user_id'] == user_id]['movie_id'].values
    all_movie_ids = movies['movie_id'].values

    cf_scores = {}

    for movie_id in all_movie_ids:
        if movie_id not in rated_movies:
            pred = model.predict(user_id, movie_id)
            cf_scores[movie_id] = pred.est  # predicted rating

    return cf_scores

"""Content based score function"""

def get_content_scores(user_id):

    #Compute content similarity score based on movies user liked

    user_ratings = ratings[ratings['user_id'] == user_id]

    liked_movies = user_ratings[user_ratings['rating'] >= 4]['movie_id'].values

    content_scores = {}

    for movie_id in movies['movie_id']:
        if movie_id not in liked_movies:
            score = 0
            for liked_movie in liked_movies:
                if liked_movie in genre_similarity_df.index:
                    score += genre_similarity_df.loc[liked_movie, movie_id]
            content_scores[movie_id] = score

    return content_scores

"""Normalising scores"""

def normalize_scores(score_dict):
    values = np.array(list(score_dict.values()))
    min_val, max_val = values.min(), values.max()

    if max_val - min_val == 0:
        return score_dict

    return {
        k: (v - min_val) / (max_val - min_val)
        for k, v in score_dict.items()
    }

"""Hybrid recommender"""

def hybrid_recommender(user_id, top_n=10, alpha=0.7):

    #Hybrid score = alpha * CF + (1 - alpha) * Content

    cf_scores = get_cf_scores(user_id)
    content_scores = get_content_scores(user_id)

    cf_scores = normalize_scores(cf_scores)
    content_scores = normalize_scores(content_scores)

    hybrid_scores = {}

    for movie_id in cf_scores:
        hybrid_scores[movie_id] = (
            alpha * cf_scores.get(movie_id, 0) +
            (1 - alpha) * content_scores.get(movie_id, 0)
        )

    top_movies = sorted(
        hybrid_scores.items(),
        key=lambda x: x[1],
        reverse=True
    )[:top_n]

    top_movie_ids = [movie_id for movie_id, _ in top_movies]

    return movies[movies['movie_id'].isin(top_movie_ids)][
        ['movie_id', 'title']
    ]

"""Testing hybrid recommender"""

hybrid_recommender(user_id=1, top_n=10, alpha=0.7)

"""# **Phase 7 : Evaluation & Comparison**"""

import random
random.seed(42)
np.random.seed(42)

"""Defining leave-one-out-Precision@10"""

import random

def precision_at_10_leave_one_out(recommender_fn, user_id, **kwargs):
    """
    Leave-one-out evaluation:
    - Hide one liked movie
    - Recommend Top-10
    - Check if hidden movie appears
    """

    user_data = ratings[ratings['user_id'] == user_id]
    liked_movies = user_data[user_data['rating'] >= 4]['movie_id'].values

    # Skip users with no liked movies
    if len(liked_movies) == 0:
        return None

    # Randomly hide one liked movie
    hidden_movie = random.choice(liked_movies)

    # Temporarily remove this rating
    mask = ~(
        (ratings['user_id'] == user_id) &
        (ratings['movie_id'] == hidden_movie)
    )
    temp_ratings = ratings[mask]

    # Swap ratings globally(temporary)
    global ratings_backup
    ratings_backup = ratings.copy()
    globals()['ratings'] = temp_ratings

    # Get recommendations
    recs = recommender_fn(user_id, top_n=10, **kwargs)

    # Restore original ratings
    globals()['ratings'] = ratings_backup

    # Check hit
    return int(hidden_movie in recs['movie_id'].values)

"""Evaluating a model across users"""

def evaluate_model(recommender_fn, users, **kwargs):
    scores = []

    for user_id in users:
        hit = precision_at_10_leave_one_out(
            recommender_fn,
            user_id,
            **kwargs
        )
        if hit is not None:
            scores.append(hit)

    return np.mean(scores)

"""Create a wrapper for popularity eval"""

def popularity_recommender_wrapper(user_id, top_n=10):
    # user_id is ignored (popularity is non-personalized)
    return popularity_recommender(top_n=top_n)

"""Run evaluation"""

test_users = ratings['user_id'].unique()[:50]

popularity_score = evaluate_model(popularity_recommender_wrapper, test_users)
cf_score = evaluate_model(svd_recommender, test_users)
hybrid_score = evaluate_model(hybrid_recommender, test_users, alpha=0.7)

popularity_score, cf_score, hybrid_score

"""Displaying results as a table"""

results_df = pd.DataFrame({
    'Model': ['Popularity', 'Collaborative Filtering', 'Hybrid'],
    'Precision@10': [popularity_score, cf_score, hybrid_score]
})

results_df